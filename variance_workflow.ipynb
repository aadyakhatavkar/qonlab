{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Fix for potential path issues\n",
    "import sys\n",
    "import os\n",
    "ROOT = os.path.dirname(os.path.abspath(''))\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "\n",
    "# Import our modular variance components\n",
    "from dgps.static import simulate_variance_break\n",
    "from estimators.forecasters import (\n",
    "    forecast_variance_dist_arima_global,\n",
    "    forecast_variance_dist_arima_rolling,\n",
    "    forecast_garch_variance,\n",
    "    variance_rmse_mae_bias,\n",
    "    variance_interval_coverage,\n",
    "    variance_log_score_normal,\n",
    ")\n",
    "from analyses.simulations import (\n",
    "    mc_variance_breaks,\n",
    "    mc_variance_breaks_grid\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca576783",
   "metadata": {},
   "source": [
    "# Variance Break Analysis Workflow\n",
    "\n",
    "This notebook provides a comprehensive workflow for analyzing variance breaks using the Pesaran (2013) framework.\n",
    "\n",
    "## Contents:\n",
    "1. **Quick Run** - Execute a small test variance break experiment\n",
    "2. **Single Variance Break Analysis** - Full Monte Carlo simulation with multiple forecasting methods\n",
    "3. **Grid Analysis** - Optimal window selection for different break magnitudes\n",
    "4. **Loss Surface Visualization** - Heatmaps showing RMSE, coverage, and log-score\n",
    "5. **Results Loading & Inspection** - Load and display saved results\n",
    "6. **Plotting Utilities** - Generate diagnostic plots from results\n",
    "7. **Tests** - Run the test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28099d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 1: Quick Run (Development)\n",
    "\n",
    "# Run a quick variance break experiment (small n_sim and T for fast iteration)\n",
    "df_point_quick, df_unc_quick = mc_variance_breaks(\n",
    "    n_sim=10,\n",
    "    T=100,\n",
    "    phi=0.6,\n",
    "    window=20,\n",
    "    horizon=5,\n",
    "    scenarios=[\n",
    "        {\"name\": \"Single variance break (quick)\", \"variance_Tb\": 50, \"variance_sigma1\": 1.0, \"variance_sigma2\": 2.0, \"task\": \"variance\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=== QUICK RUN: POINT METRICS ===\")\n",
    "print(df_point_quick.round(4).to_string(index=False))\n",
    "print(\"\\n=== QUICK RUN: UNCERTAINTY METRICS ===\")\n",
    "print(df_unc_quick.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6ed5f",
   "metadata": {},
   "source": [
    "## Section 2: Single Variance Break Simulation\n",
    "\n",
    "Run a full Monte Carlo simulation for a single variance break scenario.\n",
    "\n",
    "**Scenario Details:**\n",
    "- Single break at midpoint: $T_b = T/2$\n",
    "- Pre-break variance: $\\sigma_1 = 1.0$\n",
    "- Post-break variance: $\\sigma_2 = 2.0$ (2x increase)\n",
    "- AR(1) coefficient: $\\phi = 0.6$\n",
    "- Forecast horizon: 20 periods\n",
    "- Rolling window size: 100\n",
    "\n",
    "**Models Compared:**\n",
    "1. **ARIMA Global** - Uses full sample to estimate parameters\n",
    "2. **ARIMA Rolling** - Uses rolling window to adapt to break\n",
    "3. **GARCH** - Estimates conditional heteroskedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f8b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 2a: Run Full Monte Carlo Simulation\n",
    "\n",
    "# Run full variance break experiment (default parameters)\n",
    "df_point, df_unc = mc_variance_breaks(\n",
    "    n_sim=200,\n",
    "    T=400,\n",
    "    phi=0.6,\n",
    "    window=100,\n",
    "    horizon=20,\n",
    "    scenarios=[\n",
    "        {\"name\": \"Single variance break\", \"variance_Tb\": 200, \"variance_sigma1\": 1.0, \"variance_sigma2\": 2.0, \"task\": \"variance\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=== POINT METRICS: RMSE, MAE, BIAS ===\")\n",
    "print(df_point.round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\n=== UNCERTAINTY METRICS: COVERAGE & LOG-SCORE ===\")\n",
    "print(df_unc.round(4).to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(\"Best model (lowest RMSE):\")\n",
    "rmse_row = df_point[df_point['Metric'] == 'RMSE'].iloc[0]\n",
    "model_rmses = {col: rmse_row[col] for col in ['ARIMA Global', 'ARIMA Rolling', 'GARCH'] if col in rmse_row}\n",
    "best_model = min(model_rmses, key=model_rmses.get)\n",
    "print(f\"  {best_model}: {model_rmses[best_model]:.4f}\")\n",
    "\n",
    "print(\"\\nBest model (highest log-score):\")\n",
    "ls_row = df_unc[df_unc['Metric'] == 'LogScore'].iloc[0]\n",
    "model_ls = {col: ls_row[col] for col in ['ARIMA Global', 'ARIMA Rolling', 'GARCH'] if col in ls_row}\n",
    "best_model_ls = max(model_ls, key=model_ls.get)\n",
    "print(f\"  {best_model_ls}: {model_ls[best_model_ls]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92a395",
   "metadata": {},
   "source": [
    "## Section 3: Grid Analysis - Optimal Window Selection\n",
    "\n",
    "Analyze how forecast performance varies with rolling window size and break magnitude.\n",
    "\n",
    "**Key insight from Pesaran (2013):**\n",
    "- Larger breaks require **smaller windows** to quickly adapt\n",
    "- Smaller breaks can use **larger windows** for stability\n",
    "- This creates a trade-off in window selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 3a: Run Grid Analysis\n",
    "\n",
    "# Grid analysis: vary window size and break magnitude\n",
    "df_grid = mc_variance_breaks_grid(\n",
    "    n_sim=50,\n",
    "    T=200,\n",
    "    phi=0.6,\n",
    "    horizon=20,\n",
    "    window_sizes=[20, 50, 100, 200],\n",
    "    break_magnitudes=[1.5, 2.0, 3.0, 5.0],\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"=== LOSS SURFACE: RMSE (lower is better) ===\")\n",
    "rmse_pivot = df_grid.pivot(index='Window', columns='BreakMagnitude', values='RMSE')\n",
    "print(rmse_pivot.round(4).to_string())\n",
    "\n",
    "print(\"\\n=== LOSS SURFACE: Coverage95 (closer to 0.95 is better) ===\")\n",
    "cov_pivot = df_grid.pivot(index='Window', columns='BreakMagnitude', values='Coverage95')\n",
    "print(cov_pivot.round(4).to_string())\n",
    "\n",
    "print(\"\\n=== LOSS SURFACE: LogScore (higher is better) ===\")\n",
    "ls_pivot = df_grid.pivot(index='Window', columns='BreakMagnitude', values='LogScore')\n",
    "print(ls_pivot.round(4).to_string())\n",
    "\n",
    "# Insights\n",
    "print(\"\\n=== INSIGHTS ===\")\n",
    "print(\"Window selection trade-off:\")\n",
    "for break_mag in [1.5, 2.0, 3.0, 5.0]:\n",
    "    subset = df_grid[df_grid['BreakMagnitude'] == break_mag]\n",
    "    best_idx = subset['RMSE'].idxmin()\n",
    "    best_window = subset.loc[best_idx, 'Window']\n",
    "    print(f\"  Break magnitude {break_mag}x: optimal window ≈ {best_window}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fe338",
   "metadata": {},
   "source": [
    "## Section 4: Loss Surface Visualization\n",
    "\n",
    "Create heatmaps showing the RMSE, coverage, and log-score loss surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a168d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 4a: Plot Loss Surfaces\n",
    "\n",
    "# Create heatmap visualizations from grid results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Extract data for heatmaps\n",
    "windows = sorted(df_grid['Window'].unique())\n",
    "break_mags = sorted(df_grid['BreakMagnitude'].unique())\n",
    "\n",
    "rmse_data = df_grid.pivot(index='Window', columns='BreakMagnitude', values='RMSE')\n",
    "cov_data = df_grid.pivot(index='Window', columns='BreakMagnitude', values='Coverage95')\n",
    "ls_data = df_grid.pivot(index='Window', columns='BreakMagnitude', values='LogScore')\n",
    "\n",
    "# RMSE heatmap\n",
    "sns.heatmap(rmse_data, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=axes[0], cbar_kws={'label': 'RMSE'})\n",
    "axes[0].set_title('RMSE (lower is better)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Break Magnitude')\n",
    "axes[0].set_ylabel('Window Size')\n",
    "\n",
    "# Coverage heatmap\n",
    "sns.heatmap(cov_data, annot=True, fmt='.3f', cmap='RdYlGn', ax=axes[1], vmin=0.85, vmax=0.95, \n",
    "            cbar_kws={'label': 'Coverage'})\n",
    "axes[1].set_title('Coverage 95% (target = 0.95)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Break Magnitude')\n",
    "axes[1].set_ylabel('Window Size')\n",
    "\n",
    "# Log-score heatmap\n",
    "sns.heatmap(ls_data, annot=True, fmt='.4f', cmap='RdYlGn', ax=axes[2], cbar_kws={'label': 'Log-Score'})\n",
    "axes[2].set_title('Log-Score (higher is better)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Break Magnitude')\n",
    "axes[2].set_ylabel('Window Size')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/variance_loss_surfaces.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved figures/variance_loss_surfaces.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c803d8",
   "metadata": {},
   "source": [
    "## Section 5: Load and Inspect Saved Results\n",
    "\n",
    "Load previously saved results from the `results/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a858c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 5a: Load Latest Results\n",
    "\n",
    "# Load the most recent variance experiment results\n",
    "res_files = sorted(glob('results/variance_*_point.csv'))\n",
    "if not res_files:\n",
    "    print('No result files found in results/. Run mc_variance_breaks() to produce results.')\n",
    "else:\n",
    "    latest_point = res_files[-1]\n",
    "    latest_unc = latest_point.replace('_point.csv', '_unc.csv')\n",
    "    \n",
    "    print(f'Loading latest results:\\n  {latest_point}\\n  {latest_unc}\\n')\n",
    "    \n",
    "    df_results_point = pd.read_csv(latest_point)\n",
    "    print(\"=== POINT METRICS ===\")\n",
    "    print(df_results_point.round(4).to_string(index=False))\n",
    "    \n",
    "    if Path(latest_unc).exists():\n",
    "        df_results_unc = pd.read_csv(latest_unc)\n",
    "        print(\"\\n=== UNCERTAINTY METRICS ===\")\n",
    "        print(df_results_unc.round(4).to_string(index=False))\n",
    "    else:\n",
    "        print(f'\\nWarning: Uncertainty file not found: {latest_unc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef277b5c",
   "metadata": {},
   "source": [
    "## Section 6: Plotting Utilities\n",
    "\n",
    "Generate diagnostic plots from results (RMSE comparison, coverage analysis, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41850a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 6a: RMSE and Coverage Comparison Plots\n",
    "\n",
    "# Create comparison plots for point and uncertainty metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: RMSE Comparison\n",
    "rmse_data = df_results_point[df_results_point['Metric'] == 'RMSE']\n",
    "scenarios = rmse_data['Scenario'].unique()\n",
    "models = [col for col in df_results_point.columns if col not in ['Scenario', 'Metric']]\n",
    "\n",
    "x = np.arange(len(scenarios))\n",
    "width = 0.25\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    values = [rmse_data[rmse_data['Scenario'] == s][model].values[0] if model in rmse_data.columns else np.nan \n",
    "              for s in scenarios]\n",
    "    axes[0, 0].bar(x + i*width, values, width, label=model)\n",
    "\n",
    "axes[0, 0].set_ylabel('RMSE', fontweight='bold')\n",
    "axes[0, 0].set_title('Root Mean Squared Error Comparison', fontweight='bold')\n",
    "axes[0, 0].set_xticks(x + width)\n",
    "axes[0, 0].set_xticklabels(scenarios, rotation=20, ha='right')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: MAE Comparison\n",
    "mae_data = df_results_point[df_results_point['Metric'] == 'MAE']\n",
    "for i, model in enumerate(models):\n",
    "    values = [mae_data[mae_data['Scenario'] == s][model].values[0] if model in mae_data.columns else np.nan \n",
    "              for s in scenarios]\n",
    "    axes[0, 1].bar(x + i*width, values, width, label=model)\n",
    "\n",
    "axes[0, 1].set_ylabel('MAE', fontweight='bold')\n",
    "axes[0, 1].set_title('Mean Absolute Error Comparison', fontweight='bold')\n",
    "axes[0, 1].set_xticks(x + width)\n",
    "axes[0, 1].set_xticklabels(scenarios, rotation=20, ha='right')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: Coverage 80%\n",
    "if 'Coverage80' in df_results_unc['Metric'].values:\n",
    "    cov80_data = df_results_unc[df_results_unc['Metric'] == 'Coverage80']\n",
    "    for i, model in enumerate(models):\n",
    "        values = [cov80_data[cov80_data['Scenario'] == s][model].values[0] if model in cov80_data.columns else np.nan \n",
    "                  for s in scenarios]\n",
    "        axes[1, 0].bar(x + i*width, values, width, label=model)\n",
    "    axes[1, 0].axhline(y=0.80, color='red', linestyle='--', linewidth=2, label='Target (0.80)')\n",
    "    axes[1, 0].set_ylabel('Coverage', fontweight='bold')\n",
    "    axes[1, 0].set_title('80% Interval Coverage', fontweight='bold')\n",
    "    axes[1, 0].set_xticks(x + width)\n",
    "    axes[1, 0].set_xticklabels(scenarios, rotation=20, ha='right')\n",
    "    axes[1, 0].set_ylim([0, 1.1])\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4: Coverage 95%\n",
    "if 'Coverage95' in df_results_unc['Metric'].values:\n",
    "    cov95_data = df_results_unc[df_results_unc['Metric'] == 'Coverage95']\n",
    "    for i, model in enumerate(models):\n",
    "        values = [cov95_data[cov95_data['Scenario'] == s][model].values[0] if model in cov95_data.columns else np.nan \n",
    "                  for s in scenarios]\n",
    "        axes[1, 1].bar(x + i*width, values, width, label=model)\n",
    "    axes[1, 1].axhline(y=0.95, color='red', linestyle='--', linewidth=2, label='Target (0.95)')\n",
    "    axes[1, 1].set_ylabel('Coverage', fontweight='bold')\n",
    "    axes[1, 1].set_title('95% Interval Coverage', fontweight='bold')\n",
    "    axes[1, 1].set_xticks(x + width)\n",
    "    axes[1, 1].set_xticklabels(scenarios, rotation=20, ha='right')\n",
    "    axes[1, 1].set_ylim([0, 1.1])\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/variance_metrics_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved figures/variance_metrics_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b0b54",
   "metadata": {},
   "source": [
    "## Section 7: Diagnostics - Single Simulation Walkthrough\n",
    "\n",
    "Examine a single simulated path to understand the data-generating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 7a: Visualize Single Path with Variance Break\n",
    "\n",
    "# Generate a single variance break path with seed for reproducibility\n",
    "T = 400\n",
    "variance_Tb = 200\n",
    "y_single = simulate_variance_break(T=T, variance_Tb=variance_Tb, phi=0.6, variance_sigma1=1.0, variance_sigma2=2.0, seed=42)\n",
    "\n",
    "# Split into train/test\n",
    "horizon = 20\n",
    "y_train = y_single[:-horizon]\n",
    "y_test = y_single[-horizon:]\n",
    "\n",
    "# Generate forecasts using all three methods\n",
    "m_global, v_global = forecast_variance_dist_arima_global(y_train, horizon=horizon)\n",
    "m_rolling, v_rolling = forecast_variance_dist_arima_rolling(y_train, window=100, horizon=horizon)\n",
    "try:\n",
    "    m_garch, v_garch = forecast_garch_variance(y_train, horizon=horizon)\n",
    "    has_garch = True\n",
    "except:\n",
    "    has_garch = False\n",
    "    m_garch = np.full(horizon, np.nan)\n",
    "    v_garch = np.full(horizon, np.nan)\n",
    "\n",
    "# Plot the path\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Panel 1: Full series with variance break\n",
    "time = np.arange(T)\n",
    "axes[0].plot(time[:variance_Tb], y_single[:variance_Tb], 'o-', label='Pre-break (σ=1.0)', linewidth=1, markersize=3, alpha=0.7)\n",
    "axes[0].plot(time[variance_Tb:], y_single[variance_Tb:], 'o-', label='Post-break (σ=2.0)', linewidth=1, markersize=3, alpha=0.7, color='orange')\n",
    "axes[0].axvline(x=variance_Tb, color='red', linestyle='--', linewidth=2, label='Break point')\n",
    "axes[0].fill_between(time[variance_Tb:], -2*np.std(y_single), 2*np.std(y_single), alpha=0.1, color='red')\n",
    "axes[0].set_ylabel('$y_t$', fontweight='bold')\n",
    "axes[0].set_title('Single Variance Break Path (T=400, Tb=200, σ₁=1.0, σ₂=2.0)', fontweight='bold')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Panel 2: Forecast comparison\n",
    "test_time = np.arange(T-horizon, T)\n",
    "axes[1].plot(test_time, y_test, 'ko-', label='Actual', linewidth=2, markersize=6)\n",
    "axes[1].plot(test_time, m_global, 's--', label='ARIMA Global', linewidth=1.5, markersize=5)\n",
    "axes[1].plot(test_time, m_rolling, '^--', label='ARIMA Rolling', linewidth=1.5, markersize=5)\n",
    "if has_garch:\n",
    "    axes[1].plot(test_time, m_garch, 'D--', label='GARCH', linewidth=1.5, markersize=5)\n",
    "\n",
    "# Add 95% intervals for rolling window\n",
    "axes[1].fill_between(test_time, m_rolling - 1.96*np.sqrt(v_rolling), m_rolling + 1.96*np.sqrt(v_rolling), \n",
    "                     alpha=0.2, label='95% PI (Rolling)')\n",
    "\n",
    "axes[1].set_ylabel('Forecast', fontweight='bold')\n",
    "axes[1].set_xlabel('Time', fontweight='bold')\n",
    "axes[1].set_title('Forecast Comparison on Test Set (h=20)', fontweight='bold')\n",
    "axes[1].legend(loc='best')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/variance_single_path.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved figures/variance_single_path.png\")\n",
    "\n",
    "# Print forecast metrics for this single path\n",
    "print(\"\\n=== SINGLE PATH FORECAST METRICS ===\")\n",
    "rmse_g, mae_g, bias_g = variance_rmse_mae_bias(y_test, m_global)\n",
    "rmse_r, mae_r, bias_r = variance_rmse_mae_bias(y_test, m_rolling)\n",
    "rmse_garch, mae_garch, bias_garch = variance_rmse_mae_bias(y_test, m_garch)\n",
    "\n",
    "print(f\"ARIMA Global:  RMSE={rmse_g:.4f}, MAE={mae_g:.4f}, Bias={bias_g:.4f}\")\n",
    "print(f\"ARIMA Rolling: RMSE={rmse_r:.4f}, MAE={mae_r:.4f}, Bias={bias_r:.4f}\")\n",
    "if has_garch:\n",
    "    print(f\"GARCH:         RMSE={rmse_garch:.4f}, MAE={mae_garch:.4f}, Bias={bias_garch:.4f}\")\n",
    "\n",
    "# Coverage analysis\n",
    "cov80_r = variance_interval_coverage(y_test, m_rolling, v_rolling, level=0.80)\n",
    "cov95_r = variance_interval_coverage(y_test, m_rolling, v_rolling, level=0.95)\n",
    "ls_r = variance_log_score_normal(y_test, m_rolling, v_rolling)\n",
    "\n",
    "print(f\"\\n=== ROLLING WINDOW UNCERTAINTY ===\")\n",
    "print(f\"80% Coverage: {cov80_r:.4f} (target: 0.80)\")\n",
    "print(f\"95% Coverage: {cov95_r:.4f} (target: 0.95)\")\n",
    "print(f\"Log-Score:    {ls_r:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c4fce",
   "metadata": {},
   "source": [
    "## Section 8: Tests\n",
    "\n",
    "Run the test suite to validate the variance analysis modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 8a: Run Test Suite\n",
    "\n",
    "# Run pytest on variance-related tests\n",
    "import subprocess\n",
    "\n",
    "print(\"Running pytest on variance tests...\\n\")\n",
    "result = subprocess.run(\n",
    "    ['pytest', 'tests/test_variance_garch.py', 'tests/test_scenarios.py', '-v'],\n",
    "    capture_output=False,\n",
    "    check=False\n",
    ")\n",
    "print(f\"\\nTest result: {'PASSED' if result.returncode == 0 else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff017609",
   "metadata": {},
   "source": [
    "## Section 9: References and Notes\n",
    "\n",
    "**Key Papers:**\n",
    "- Pesaran, M. H. (2013). \"Forecasting Economic Time Series.\" MIT Press.\n",
    "- Diebold, F. X., & Mariano, R. S. (1995). \"Comparing Predictive Accuracy.\" Journal of Business & Economic Statistics.\n",
    "\n",
    "**Methodology:**\n",
    "- **Data-Generating Process**: AR(1) with variance break at $T_b$\n",
    "- **Forecasting Methods**:\n",
    "  - ARIMA Global: Estimates parameters on full sample (ignores break)\n",
    "  - ARIMA Rolling: Uses rolling window to adapt to break (robust but noisier)\n",
    "  - GARCH: Models conditional heteroskedasticity explicitly\n",
    "\n",
    "**Key Insights:**\n",
    "1. Rolling windows are essential for robust forecasting after breaks\n",
    "2. Window size must be adapted to break magnitude (window-break trade-off)\n",
    "3. Larger breaks require smaller windows for quick adaptation\n",
    "4. Smaller breaks allow larger windows for better stability\n",
    "\n",
    "**Next Steps:**\n",
    "- Compare with real financial data (S&P 500, forex, etc.)\n",
    "- Extend to multiple structural breaks\n",
    "- Adaptive window selection algorithms\n",
    "- Integration with portfolio optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f2fcb",
   "metadata": {},
   "source": [
    "## Notes and next steps\n",
    "\n",
    "- Consider adding a cell to save the raw per-simulation outputs (`--save-raw`) so analysts can compute additional diagnostics and plots.\n",
    "- If you want multi-core speedups, add an `--n-jobs` flag to `pixi.py` and pass it into `mc_variance_breaks`.\n",
    "- For publication-quality plots, create a dedicated notebook that reads `results/` and produces figures with a shared matplotlib style or seaborn.\n",
    "\n",
    "If you'd like, I can add a `--save-raw` option to `pixi.py` and a dedicated analysis notebook that demonstrates common plots (RMSE comparison, coverage over time, QQ plots of residuals)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

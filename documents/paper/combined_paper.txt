Monte Carlo Simulation of Predictive Stability
under Structural Breaks
Aadya Khatavkar (50196397)
Bakhodir Izzatulloev (50294516)
Mahir Baylarov (50316809)
University of Bonn
Research Module in Econometrics and Statistics
Fundamentals of Monte Carlo Simulations
Winter Semester 2025/26

1

Introduction

The assumption of parameter stability is fundamental to statistical forecasting. In practice,
however, the relationships captured by model parameters often change over time. Economic
structures, institutions, and policy regimes evolve, and when they do, the underlying datagenerating process may shift accordingly. As a result, time series frequently exhibit structural
breaks. Because forecasting plays a central role in planning, investment decisions, and policy analysis in both the public and private sectors, understanding the impact of structural
instability on predictive performance is of primary importance.
A substantial body of literature examines structural breaks and their implications for
inference and estimation. Empirical evidence suggests that nancial and macroeconomic
relationships are often unstable, and forecasting models that perform well in-sample may fail
to deliver comparable improvements out-of-sample once the underlying relationship changes
(Stock and Watson, 1996; Clark and McCracken, 2001). Much of the economic research
on structural breaks has focused on detection, estimation, and inference in the presence of
breaks (e.g., Andrews and Kitagawa; Killick, Fearnhead, and Eckley, 2012). While these
contributions are essential, the forecasting problem presents a distinct challenge. In real
time, breakpoints are typically unknown, and forecasters must rely on methods that are
robust to potential instability.
This raises a natural question: how sensitive are dierent forecasting models to alternative
forms of structural change? In particular, do models that explicitly account for regime shifts
outperform simpler adaptive procedures, and under what conditions?
To address this question, this paper employs a Monte Carlo simulation framework to
evaluate forecasting accuracy under controlled structural break scenarios. Simulation-based
analysis is particularly suitable for this purpose because it allows the researcher to operate
1

in an environment where the true data-generating process is known. By construction, we
isolate specic types of instabilitymean shifts, changes in autoregressive persistence, and
volatility shiftswhile holding other features constant. In contrast, empirical time series
typically exhibit multiple overlapping sources of instability, making it dicult to identify
the precise mechanism driving forecast deterioration.
The main contribution of this paper is a systematic comparison of dierent forecasting
approaches across multiple structural break designs. We consider (i) globally estimated linear
time-series models that impose parameter constancy (Global SARIMA), (ii) adaptive rollingwindow estimation procedures that re-estimate parameters using only recent observations
(Rolling SARIMA), and (iii) regime-switching models that explicitly allow parameters to
depend on an unobserved state variable (Markov-switching AR). Forecast performance is
primarily evaluated using RMSE, MAE, and bias. In selected designs, we further vary
the innovation distribution (Gaussian and Student-t with dierent degrees of freedom) and,
for recurring breaks, the level of regime persistence in order to examine how distributional
assumptions and switching dynamics aect predictive stability.
The remainder of the paper is organized as follows. Section 2 reviews the literature on
simulation-based forecasting environments, structural breaks, and forecast stability. Section
3 describes the data-generating processes and forecasting design. Section 4 presents the
forecasting methods and evaluation metrics. Section 5 presents the Monte Carlo results for
single and recurring break scenarios and discusses the relative performance of the competing
forecasting methods. Section 6 concludes.

2

Literature Review

2.1

Structural Breaks and Forecasting Under Instability

Structural change has long been recognized as a central issue in time-series econometrics.
Perron (1989) shows that ignoring structural breaks may lead to misleading conclusions regarding persistence and stationarity. This insight motivated the development of formal break
detection methods. Bai and Perron (1998, 2003) provide procedures for identifying and estimating multiple structural breaks in linear models, while Hansen (2001) develops inference
tools applicable in unstable environments. These contributions establish that parameter
instability must be explicitly addressed to maintain reliable econometric inference.
Beyond detection, structural breaks have direct implications for forecasting performance.
When parameters shift over time, models estimated on the full sample implicitly assume
stability and may produce biased or inecient forecasts. In long time series, changes in
autoregressive dynamics aect both short-run predictions and shock propagation. Stock
and Watson (1996) document widespread instability in macroeconomic forecasting models,
showing that strong in-sample performance does not guarantee out-of-sample gains. Clark
and McCracken further develop statistical procedures to evaluate predictive improvements
under structural change, highlighting the diculty of achieving consistent forecast accuracy
in unstable environments.
More recent research focuses on improving forecast construction under instability. Pesaran et al. (2011) show that weighting observations can reduce mean squared forecast error
2

in the presence of both discrete and continuous breaks. Tian (2011) proposes weighting
schemes based on structural break tests, emphasizing adaptability to recent regime changes.
These approaches formalize the biasvariance trade-o inherent in unstable environments:
reducing the inuence of outdated observations lowers bias but increases estimation variance.
The magnitude and persistence of breaks also matter. HÃ¤nninen (2018), using Monte
Carlo simulations, nds that forecasting performance depends on whether parameter shifts
are small, moderate, or persistent. Taken together, this literature suggests that forecasting under structural instability requires balancing exibility and eciency, and that model
performance depends on the specic nature of the break process.

2.2

Monte Carlo Simulation as a Tool for Predictive Stability

Because structural breaks are typically unobserved and may overlap in empirical data, Monte
Carlo simulation provides a natural framework for studying predictive stability under controlled conditions.
Monte Carlo simulation involves generating articial time series from a known datagenerating process (DGP) and repeatedly estimating forecasting models on these simulated
samples. By averaging results across many replications, researchers obtain stable measures
of forecast performance under clearly dened instability scenarios. Since the true parameters are known, forecast bias, root mean squared error (RMSE), and error variance can be
evaluated directly.
An important advantage of simulation is the ability to isolate dierent break mechanisms.
For example, a single mean shift can be introduced while holding persistence and volatility
constant, or recurring parameter changes can be analyzed independently of distributional assumptions. By varying break timing, magnitude, and persistence systematically, simulation
enables a transparent comparison of forecasting strategies across structural environments.
Monte Carlo evidence in Clark and McCracken (2003) and Pesaran, Pick, and Timmermann (2013) illustrates how predictive performance depends critically on the form and
persistence of structural change. In this study, simulation is used to compare global, rolling,
and break-adjusted forecasting approaches across mean, parameter, and variance break designs, allowing the isolated impact of instability to be assessed.

2.3

Adaptive and Regime-Switching Forecasting Models

The presence of structural instability has motivated forecasting methods that either adapt
to change or model regime variation explicitly.
Adaptive approaches, such as rolling-window estimation, restrict parameter estimation
to recent observations. By reducing the inuence of outdated regimes, rolling methods
decrease post-break bias, though at the cost of higher estimation variance. This trade-o is
emphasized by Clements and Hendry (1998). Exponential smoothing techniques developed
by Holt (1957) and Winters (1960), systematized and evaluated in the forecasting literature
by Gardner (1985), and later formalized within state-space frameworks by Hyndman and
Athanasopoulos (2018), assign declining weights to older observations, allowing forecasts to
adjust gradually when structural shifts occur.

3

Regime-switching models incorporate structural change directly into the data-generating
process. The Markov-switching framework of Hamilton (1989) allows parameters to vary
across latent states governed by a transition process. By estimating regime probabilities,
these models generate forecasts that account for possible regime changes and are particularly
suited to recurring and persistent instability.
The literature does not identify a universally superior approach. Fixed-parameter models
perform well under stability but deteriorate after breaks. Adaptive methods improve exibility yet may lose eciency in stable periods. Regime-switching models provide structural
interpretation but require suciently distinct regimes to yield gains. Forecast performance
therefore depends on how closely the chosen method aligns with the underlying break structure.

3

Data Generating Process

This section describes the data-generating processes (DGPs) used in the Monte Carlo experiments. All simulations are based on univariate AR(1) processes of length T = 400. In
single-break designs, the structural break occurs at Tb = 200. Each experiment isolates a single dimension of structural instabilitymean, variance, or autoregressive parameterwhile
holding all remaining features constant. All regimes satisfy |Ï•| < 1, ensuring covariance
stationarity.
Let {yt }Tt=1 denote the simulated process. The baseline specication is given by

yt = Âµt + Ï•t (ytâˆ’1 âˆ’ Âµt ) + Îµt ,

(1)

where Âµt denotes the regime-dependent mean, Ï•t the autoregressive coecient, and Îµt the
innovation term.
Innovations are drawn either from a Gaussian distribution or from a standardized Studentt distribution with degrees of freedom Î½ âˆˆ {3, 5}. In the latter case, shocks are rescaled to
have unit variance to ensure comparability across innovation types. Unless stated otherwise,
the innovation variance equals one.

3.1

Single Structural Break Designs

In the deterministic single-break setting, parameters shift once at t = Tb .

3.1.1 Mean Break
The mean break design is dened as

yt = Âµt + Ï•(ytâˆ’1 âˆ’ Âµt ) + Îµt ,

(2)

with constant persistence Ï• = 0.6 and

(
0, t â‰¤ Tb ,
Âµt =
2, t > Tb .

(3)

The break therefore induces a discrete upward shift in the unconditional mean, while persistence and innovation variance remain unchanged.
4

3.1.2 Variance Break
Variance instability is introduced through

where Âµ = 0, Ï• = 0.6, and

yt = Âµ + Ï•(ytâˆ’1 âˆ’ Âµ) + Îµt ,

(4)

(
D(0, Ïƒ12 ), t â‰¤ Tb ,
Îµt âˆ¼
D(0, Ïƒ22 ), t > Tb ,

(5)

with Ïƒ1 = 1 and Ïƒ2 = 2. The structural break thus increases the innovation variance from 1
to 4 while leaving the conditional mean dynamics unchanged.

3.1.3 Parameter Break
In the parameter break design, persistence changes at Tb :

with

yt = Ï•t ytâˆ’1 + Îµt ,

(6)

(
0.2, t â‰¤ Tb ,
Ï•t =
0.9, t > Tb .

(7)

The break represents a transition from weak persistence to highly persistent near-unit-root
dynamics, while the mean and innovation variance remain constant.

3.2

Recurring (Markov-Switching) Break Designs

To model recurring structural instability, a latent regime indicator St âˆˆ {0, 1} evolves according to a rst-order Markov chain with transition probabilities

P (St = i | Stâˆ’1 = i) = pii .

(8)

Unless otherwise specied, transition probabilities are symmetric, p00 = p11 = 0.95,
implying an expected regime duration of approximately 1/(1 âˆ’ 0.95) = 20 periods.

3.2.1 Recurring Mean Break
The observation equation becomes

yt = ÂµSt + Ï•(ytâˆ’1 âˆ’ ÂµSt ) + Îµt ,

(9)

with Âµ0 = 0, Âµ1 = 2, and Ï• = 0.6. Regime changes therefore induce stochastic shifts in the
unconditional mean while persistence and variance remain constant.

5

Figure 1: Recurring Mean Break DGP

3.2.2 Recurring Variance Break
Variance switching is modeled as

where Âµ = 0, Ï• = 0.6, and

yt = Âµ + Ï•(ytâˆ’1 âˆ’ Âµ) + Îµt ,

(10)

Îµt âˆ¼ N (0, ÏƒS2 t ),

(11)

with Ïƒ1 = 1 and Ïƒ2 = 2. Regime transitions generate recurrent volatility shifts without
altering the conditional mean dynamics.

6

Figure 2: Recurring Variance Break DGP

7

dgp_variance_95.png

Figure 3: Recurring Variance DGP (Markov-Switching, p=0.95)

3.2.3 Recurring Parameter Break
Persistence switching is dened by

yt = Ï•St ytâˆ’1 + Îµt ,
where Ï•0 = 0.2 and Ï•1 = 0.9.

8

(12)

Figure 4: Recurring Parameter Break DGP
In this case, regime persistence varies across experiments according to

p00 = p11 âˆˆ {0.90, 0.95, 0.99}.

(13)

Higher persistence values imply longer regime durations and therefore stronger dynamic
instability.

9

dgp_parameter_90.png

Figure 5: Recurring Parameter DGP (Markov-Switching, p=0.90)

10

dgp_parameter_95.png

Figure 6: Recurring Parameter DGP (Markov-Switching, p=0.95)

11

dgp_parameter_99.png

Figure 7: Recurring Parameter DGP (Markov-Switching, p=0.99)

3.3

Design Considerations

Each DGP isolates one structural dimensionmean, variance, or persistencewhile holding
the remaining components xed. Heavy-tailed innovations are considered in single-break
settings to evaluate robustness to non-Gaussian shocks without conating distributional
features with stochastic regime switching. Forecast instability therefore arises solely from
structural change rather than explosive dynamics or model misspecication.

12

4

Forecasting Methods and Evaluation Metrics

4.1

Forecasting Methods

Forecasts are generated in a recursive one-step-ahead framework. At each forecast origin t,
models are estimated using the available training sample and used to produce the forecast
yÌ‚t+1|t . This procedure is repeated throughout the out-of-sample period to ensure a consistent
evaluation across break types.
Unless otherwise stated, the following core forecasting models are applied across all structural break environments.

4.1.1 Core Forecasting Models
(i) Global SARIMA A SARIMA(1, 0, 1)(1, 0, 0)12 specication is estimated on the full

training sample. The seasonal period s = 12 is imposed consistently across designs to allow
for potential cyclical dynamics and to maintain comparability across break environments.
In lag-operator notation,
Î¦(L12 ) Ï•(L)yt = Î˜(L)Îµt .
(14)
Parameters are assumed constant over time and estimated using all available observations
at each forecast origin. Because it pools information across regimes, this specication serves
as a benchmark model under structural change.

(ii) Rolling SARIMA

To allow for parameter adaptation, the same SARIMA(1, 0, 1)(1, 0, 0)12
structure is estimated using a rolling window of xed length W . In the simulations, the rolling
window length is chosen to balance adaptability and estimation stability (e.g., W = 80 or
W = 100, depending on the break design).
Formally,
(W )
(15)
yÌ‚t+1|t = E (yt+1 | ytâˆ’W +1 , . . . , yt ) .
By restricting estimation to recent observations, the rolling approach reduces contamination from outdated regimes and improves responsiveness to structural shifts. However, this
comes at the cost of higher estimation variance due to the smaller eective sample.

4.1.2 Break-Specic Extensions
Additional models are introduced depending on the form of instability.

A. Mean Break Designs
(i) Markov-Switching Mean Model

The conditional mean varies across regimes:

yt = ÂµSt + Ï•(ytâˆ’1 âˆ’ ÂµSt ) + Îµt .

(16)

The one-step-ahead forecast is computed as a probability-weighted average across regimes:

yÌ‚t+1|t =

1
X

Ï€t|t (i) [Âµi + Ï•(yt âˆ’ Âµi )] ,

i=0

13

(17)

where Ï€t|t (i) denotes the ltered probability of regime i.
This model is designed to capture recurring shifts in the intercept while maintaining a
common autoregressive structure.

(ii) Break Dummy (Oracle Specication)

An exogenous dummy variable is in(
0, t â‰¤ Tb ,
Dt =
(18)
1, t > Tb .

cluded:

The dummy shifts the intercept after the known break date. Because the break timing
is assumed known, this specication provides an upper performance bound rather than a
feasible forecasting strategy.

(iii) Simple Exponential Smoothing (SES)

Forecasts are generated recursively as

yÌ‚t+1|t = Î»yt + (1 âˆ’ Î»)yÌ‚t|tâˆ’1 .

(19)

SES assigns geometrically declining weights to past observations and is particularly suited
to level shifts. It provides a fully adaptive alternative to parametric models.

B. Parameter Break Designs
AR(1) model is estimated:

To capture persistence instability, a Markov-switching

yt = Ï•St ytâˆ’1 + Îµt .

(20)

The one-step-ahead forecast is constructed as


yÌ‚t+1|t = Ï€t|t (0)Ï•0 + Ï€t|t (1)Ï•1 yt .

(21)

This specication directly aligns with the recurring parameter-break DGP, where persistence shifts between low and high autoregressive regimes.

C. Variance Break Designs

For volatility instability, models that produce both mean
and variance forecasts are considered.

(i) GARCH(1,1)

Conditional variance evolves according to
2
Ïƒt2 = Ï‰ + Î±1 Îµ2tâˆ’1 + Î²1 Ïƒtâˆ’1
.

(22)

The one-step-ahead variance forecast is
2
ÏƒÌ‚t+1|t
= Ï‰ + Î±1 Îµ2t + Î²1 Ïƒt2 .

(23)

This model explicitly captures time-varying volatility and is therefore structurally consistent with variance-break environments.

14

(ii) Markov-Switching Variance Model

Variance depends on the latent regime:

Îµt âˆ¼ N (0, ÏƒS2 t ).

(24)

2
ÏƒÌ‚t+1|t
= Ï€t|t (0)Ïƒ02 + Ï€t|t (1)Ïƒ12 .

(25)

The forecast variance is given by

This specication allows for recurring volatility regimes and provides a structural alternative to GARCH-based modeling.

4.2

Evaluation Metrics

Forecast performance is evaluated using point forecast accuracy measures. Let

et+1 = yt+1 âˆ’ yÌ‚t+1|t

(26)

denote the one-step-ahead forecast error, where yt+1 is the realized value and yÌ‚t+1|t is the
forecast formed at time t. All metrics are computed over the out-of-sample evaluation period
of length H and subsequently averaged across Monte Carlo replications.

4.2.1 Point Forecast Metrics
The primary measure of forecast accuracy is the Root Mean Squared Error (RMSE), dened
as
v
u
H
u1 X
t
RMSE =
e2 .
(27)
H t=1 t
RMSE penalizes large forecast errors disproportionately and is therefore sensitive to episodes
of heightened volatility or abrupt persistence shifts. It provides an overall measure of predictive precision.
Complementing RMSE, the Mean Absolute Error (MAE) is computed as
H

MAE =

1 X
|et |.
H t=1

(28)

MAE is less sensitive to extreme realizations and is particularly informative under heavytailed innovation distributions.
To assess systematic forecast distortion, Bias is dened as
H

1 X
Bias =
et .
H t=1

(29)

Bias measures whether forecasts tend to systematically overpredict or underpredict the realized series. This metric is especially relevant in environments with mean shifts.

15

In addition, the variance of forecast errors is reported to evaluate dispersion independently of systematic bias. It is calculated as
H

Var(e) =

1 X
(et âˆ’ eÌ„)2 ,
H t=1

where

(30)

H

1 X
et
eÌ„ =
H t=1

(31)

denotes the average forecast error. Forecast error variance captures the stability of predictions and helps distinguish improvements arising from reduced volatility of errors versus
reductions in bias.
All performance measures are averaged across Monte Carlo replications to obtain stable
comparisons across forecasting models and structural break designs.

5

Results

5.1

Mean Break Results

5.1.1 Single Mean Break
Under Gaussian innovations, the oracle specication that includes the true break dummy
achieves the lowest RMSE (0.9789), as expected. Because the break location is assumed
known, this model represents a benchmark rather than a feasible competitor. Its advantage
relative to other models stems primarily from reduced error variance (0.9336), rather than
a dramatic improvement in bias. Although its bias (0.1568) is not the smallest among the
models, its dispersion is clearly lower.
Table 1: Mean Single Break (Gaussian): 300 simulations
Method

RMSE

MAE

Bias

Var(error)

SARIMA + Break Dummy (oracle Tb)

0.9789

0.7607

0.1568

0.9336

Simple Exp. Smoothing (SES)

1.0598

0.8488

0.0644

1.1190

Holt-Winters (additive)

1.0979

0.8643

0.0266

1.2047

SARIMA Rolling

1.1424

0.9059

0.1833

1.2715

SARIMA Global

1.1482

0.8985

0.3800

1.1741

When innovations follow a Student-t distribution with three degrees of freedom, overall
forecast errors increase, and dierences between models widen. The oracle dummy again
achieves the lowest RMSE (1.1056). SES remains the best feasible model, with lower RMSE
and MAE than both rolling and global SARIMA. The performance deterioration of SARIMAbased models is accompanied by increased error variance, suggesting sensitivity to heavytailed disturbances. Bias remains positive across models, but dispersion dierences dominate
performance comparisons.
16

Table 2: Mean Single Break (Student-t df=3): 300 simulations
Method

RMSE

MAE

Bias

Var(error)

SARIMA + Break Dummy (oracle Tb)

1.1056

0.7405

0.1655

1.1950

Simple Exp. Smoothing (SES)

1.1328

0.7774

0.0644

1.2790

Holt-Winters (additive)

1.1371

0.8046

0.0457

1.2910

SARIMA Rolling

1.2195

0.8434

0.2114

1.4424

SARIMA Global

1.2284

0.8695

0.3984

1.3502

For Student-t innovations with ve degrees of freedom, results are intermediate between
the Gaussian and t(3) cases. The oracle dummy retains the lowest RMSE (1.0610). SES again
provides the strongest feasible performance, while Global SARIMA remains the weakest.
Bias values vary modestly across models, but the principal dierences arise from forecast
error variance. In all innovation settings, the global model consistently exhibits the largest
bias and one of the highest error variances, indicating that failure to adapt to the structural
shift leads to persistent overprediction after the break.
Table 3: Mean Single Break (Student-t df=5): 300 simulations
Method

RMSE

MAE

Bias

Var(error)

SARIMA + Break Dummy (oracle Tb)

1.0610

0.7785

0.1451

1.1046

Simple Exp. Smoothing (SES)

1.1278

0.8284

0.0363

1.2707

Holt-Winters (additive)

1.1599

0.8561

-0.0054

1.3454

SARIMA Rolling

1.2033

0.8659

0.2105

1.4037

SARIMA Global

1.2419

0.9227

0.3903

1.3899

Across distributions, adaptive level-based methods (SES and HoltWinters) systematically outperform rolling and global SARIMA. The primary channel of improvement is a
reduction in forecast dispersion rather than a complete elimination of bias.

5.1.2 Recurring Mean Break
We next consider stochastic switching in the mean. In this design, regimes alternate according to a Markov process, so that intercept changes occur repeatedly rather than once.
The oracle dummy remains the best-performing specication in terms of RMSE (1.0957).
However, its advantage over the other models is smaller than in the single-break case. Because the dummy captures only a deterministic shift at a xed time, it cannot fully track
repeated regime changes. This is reected in a forecast error variance (1.1997) that is closer
to those of the competing models.

17

Table 4: Mean Recurring: 300 simulations
Method

RMSE

MAE

Bias

Var(error)

SARIMA + Break Dummy (oracle Tb)

1.0957

0.8906

0.0287

1.1997

SARIMA Global

1.1253

0.9019

0.1931

1.2290

SARIMA Rolling

1.1504

0.9285

0.1919

1.2867

Simple Exp. Smoothing (SES)

1.1548

0.9101

0.0267

1.3329

Holt-Winters (additive)

1.1798

0.9235

0.0114

1.3918

Among feasible approaches, Global SARIMA achieves the lowest RMSE (1.1253), followed closely by Rolling SARIMA (1.1504). In contrast to the single-break case, smoothing
methods no longer dominate. SES and HoltWinters exhibit higher RMSE and noticeably
larger error variances. Under recurring switching, purely level-based smoothing appears less
eective because the mean alternates between regimes rather than shifting once.
Bias values across all models are small and of similar magnitude. Dierences in performance therefore stem primarily from changes in error variance. Compared to the single-break
design, dispersion is higher for all methods, reecting the additional uncertainty introduced
by stochastic regime switching.
Overall, the recurring mean results indicate that the relative advantage of adaptive
smoothing diminishes when breaks are stochastic and repeated. Models that maintain a
richer dynamic structure, such as SARIMA specications, become more competitive in this
environment.

5.2

Parameter Break Results

5.2.1 Single Parameter Break
We begin with the deterministic break in persistence, where the autoregressive coecient
shifts from Ï• = 0.2 to Ï• = 0.9 at Tb . This change represents a substantial alteration in
dynamic behavior, moving from weak serial dependence to near-unit-root persistence. The
discussion proceeds in terms of the mean forecast performance (RMSE and MAE), bias, and
forecast error variance.
Under Gaussian errors, the Markov-switching AR (MS-AR) model achieves the lowest
RMSE (1.0735), followed by Rolling SARIMA (1.0950), while Global SARIMA performs
worse (1.1702). The same ranking holds for MAE, indicating that allowing for regimedependent persistence improves overall forecast accuracy. Bias is small across all models,
suggesting that the gains are not driven by systematic correction of forecast direction. Instead, improvements arise primarily from reductions in dispersion. Forecast error variance
declines from 1.3685 under Global SARIMA to 1.1512 under MS-AR, conrming that explicit
regime modeling enhances precision rather than eliminating bias.

18

Table 5: Parameter Single Break (Gaussian): 300 simulations
Method

RMSE

MAE

Bias

Var(error)

MS AR

1.0735

0.8456

0.0353

1.1512

Rolling SARIMA

1.0950

0.8651

0.0433

1.1971

Global SARIMA

1.1702

0.9297

0.0288

1.3685

When innovations follow a Student-t distribution with three degrees of freedom, the
ranking changes. Rolling SARIMA achieves the lowest RMSE (0.9106), outperforming MSAR (1.0502) and Global SARIMA (1.0931). The reduction in forecast error variance is
particularly pronounced for the rolling specication (0.8287 compared to 1.1027 for MS-AR).
Bias remains small in magnitude for all models. Under strongly heavy-tailed shocks, rolling
estimation appears more robust, likely because it adapts mechanically to recent observations
without relying on likelihood-based regime classication, which may be sensitive to extreme
realizations.
Table 6: Parameter Single Break (Student-t df=3): 300 simulations
Method

RMSE

MAE

Bias

Var(error)

Rolling SARIMA

0.9106

0.6792

0.0212

0.8287

MS AR

1.0502

0.7118

-0.0138

1.1027

Global SARIMA

1.0931

0.7951

0.0526

1.1921

For Student-t innovations with ve degrees of freedom, the results are intermediate. MSAR again delivers the lowest RMSE (0.9653), though the margin relative to Rolling SARIMA
(0.9781) is modest. Forecast error variances are closer across models than in the Gaussian
case, and bias remains small and stable. Compared to the t(3) case, the deterioration in
MS-AR performance is less pronounced, indicating that moderate deviations from normality
do not substantially weaken the benets of explicit regime modeling.
Table 7: Parameter Single Break (Student-t df=5): 300 simulations
Method

RMSE

MAE

Bias

Var(error)

MS AR

0.9653

0.7309

0.0408

0.9302

Rolling SARIMA

0.9781

0.7510

0.0143

0.9565

Global SARIMA

1.0476

0.8032

0.0124

1.0973

Across all innovation distributions, Global SARIMA consistently exhibits the highest
RMSE and forecast error variance. Dierences in bias remain limited throughout. The
principal eect of structural adaptation is therefore variance reduction rather than systematic
correction of mean forecasts. Overall, the single-break results indicate that modeling regimedependent persistence improves forecast stability under Gaussian and moderately heavytailed shocks, while rolling estimation provides greater robustness under strongly heavytailed disturbances.
19

5.2.2 Recurring Parameter Breaks
We next consider stochastic regime switching, where the autoregressive coecient alternates
between Ï•0 = 0.2 and Ï•1 = 0.9 according to a two-state Markov process. Results are
reported for persistence levels p = 0.90, 0.95, 0.99, corresponding to increasing expected
regime durations. As before, we evaluate mean forecast performance, bias, and forecast
error variance.
When regime persistence is relatively low (p = 0.90), switching occurs frequently. In this
environment, MS-AR achieves the lowest RMSE (1.1426), while Global SARIMA (1.1695)
and Rolling SARIMA (1.1875) perform worse. The dierences across models are driven
mainly by forecast error variance. MS-AR produces the lowest variance (1.3049), compared
to 1.3676 and 1.4100 for the global and rolling specications, respectively. Bias remains
small for all methods and does not materially dierentiate performance. Under frequent
switching, explicit regime modeling primarily improves control of forecast dispersion.
Table 8: Parameter Recurring (p=09): 300 simulations
Method

RMSE

MAE

Bias

Var(error)

MS AR

1.1426

0.8922

0.0253

1.3049

Global SARIMA

1.1695

0.9117

0.0041

1.3676

Rolling SARIMA

1.1875

0.9257

0.0059

1.4100

At moderate persistence (p = 0.95), overall forecast errors decline relative to the p = 0.90
case. MS-AR continues to deliver the lowest RMSE (1.0778), though the gap relative to the
rolling approach narrows. Forecast error variance decreases for all models, consistent with
longer regime durations reducing instability. Bias uctuates slightly but remains economically small. As regimes become more persistent, recent observations carry greater informational content about current dynamics, improving the relative performance of rolling
estimation.
Table 9: Parameter Recurring (p=095): 300 simulations
Method

RMSE

MAE

Bias

Var(error)

MS AR

1.0778

0.8570

0.0408

1.1600

Rolling SARIMA

1.1215

0.8990

-0.0027

1.2578

Global SARIMA

1.1238

0.8952

-0.0114

1.2627

When persistence is high (p = 0.99), forecast errors decline further for all methods.
MS-AR again achieves the lowest RMSE (1.0318), but the dierence relative to Rolling
SARIMA (1.0668) is smaller than under lower persistence. Forecast error variances converge
across models, and bias becomes slightly negative for the global and rolling specications,
although magnitudes remain modest. With highly persistent regimes, rolling estimation
approximates within-regime dynamics more eectively, reducing the advantage of explicit
regime probability weighting.
20

Table 10: Parameter Recurring (p=099): 300 simulations
Method

RMSE

MAE

Bias

Var(error)

MS AR

1.0318

0.8043

-0.0102

1.0645

Rolling SARIMA

1.0668

0.8408

-0.0123

1.1380

Global SARIMA

1.0974

0.8515

-0.0582

1.2009

Across all persistence levels, Global SARIMA consistently exhibits higher forecast error
variance than the alternative methods. Dierences in bias remain limited, indicating that
forecast improvements stem primarily from reductions in dispersion rather than systematic
mean correction. Overall, the recurring-break results show that explicit regime modeling
yields consistent gains, particularly when switching is frequent, while rolling estimation
becomes increasingly competitive as regimes grow more persistent.

5.3

Variance Break Results

5.3.1 Single Variance Break
This subsection evaluates forecast performance when structural instability aects the innovation variance while the conditional mean dynamics remain unchanged. Results are reported
for both deterministic single variance shifts and recurring variance regimes. Emphasis is
placed on RMSE, bias, forecast error variance, and density-based measures.
Under Gaussian innovations, dierences across models are relatively small in terms of
RMSE. The SARIMA averaged-window approach achieves the lowest RMSE (2.0518), closely
followed by GARCH (2.0535). Global and Rolling SARIMA perform slightly worse. The
ranking is similar for MAE. Bias remains modest across specications, with values ranging
between 0.1884 and 0.2094, indicating limited systematic forecast distortion. The primary
dierences arise in forecast error variance and log score. The averaged-window SARIMA exhibits the lowest error variance (4.1746), while Rolling SARIMA shows the highest (4.2430).
Log scores are also slightly more favorable for the averaged-window model. Overall, under
Gaussian variance shifts, no model dominates strongly, but approaches that allow partial
adaptation to changing volatility perform marginally better.
Table 11: Variance Single Break (Gaussian): 300 simulations
Method

RMSE

MAE

Bias

Variance

LogScore

SARIMA Avg-Window

2.0518

1.6331

0.1884

4.1746

-2.2981

GARCH

2.0535

1.6338

0.2024

4.1759

-2.2569

SARIMA Global

2.0610

1.6356

0.2094

4.2040

-2.4520

SARIMA Rolling

2.0688

1.6423

0.1924

4.2430

-2.2781

When innovations follow a Student-t distribution with three degrees of freedom, GARCH
achieves the lowest RMSE (2.0311), although the dierence relative to Global SARIMA is
minimal. Forecast error variance is also lowest under GARCH (4.0423). In contrast, Rolling
and averaged-window SARIMA show higher dispersion. Bias values are somewhat larger
21

than in the Gaussian case, reecting the inuence of heavy-tailed shocks. The log predictive
score is most favorable for GARCH, suggesting improved density calibration under volatility instability combined with heavy-tailed innovations. In this setting, explicitly modeling
conditional heteroskedasticity provides measurable gains.
Table 12: Variance Single Break (Student-t df=3): 300 simulations
Method

RMSE

MAE

Bias

Variance

LogScore

GARCH

2.0311

1.3335

0.2884

4.0423

-2.1884

SARIMA Global

2.0360

1.3406

0.3010

4.0548

-2.3739

SARIMA Rolling

2.0548

1.3649

0.2966

4.1342

-2.1548

SARIMA Avg-Window

2.0576

1.3688

0.2856

4.1520

-2.2049

For Student-t innovations with ve degrees of freedom, overall forecast errors increase
relative to the Gaussian case. The averaged-window SARIMA achieves the lowest RMSE
(2.2381), though dierences across models remain small. Error variances are higher than
in the Gaussian design, and dispersion dierences become more pronounced. GARCH no
longer provides a clear advantage in RMSE, although its log score remains competitive.
Rolling SARIMA continues to exhibit comparatively higher error variance. Across distributions, improvements in this single-break variance design are modest and primarily driven by
dierences in error dispersion rather than bias reduction.
Table 13: Variance Single Break (Student-t df=5): 300 simulations
Method

RMSE

MAE

Bias

Variance

LogScore

SARIMA Avg-Window

2.2381

1.5678

0.1849

4.9751

-2.4155

GARCH

2.2438

1.5575

0.1922

4.9975

-2.3550

SARIMA Global

2.2517

1.5617

0.1993

5.0306

-2.6524

SARIMA Rolling

2.2551

1.5607

0.2086

5.0422

-2.3774

Taken together, the single variance break results indicate that modeling conditional heteroskedasticity becomes more relevant as innovation distributions deviate from normality.
However, when the variance shift is deterministic and occurs only once, the relative performance dierences across models remain limited.

5.3.2 Recurring Variance Break
The recurring variance design introduces stochastic switching between low- and high-volatility
regimes. In this environment, dierences across models become more pronounced.
Global SARIMA achieves the lowest RMSE (1.6018), closely followed by the Markovswitching AR(1) model (1.6031). Rolling and averaged-window SARIMA perform slightly
worse. Bias values are small and negative across all specications, indicating mild underprediction but no substantial systematic distortion. The key distinction lies in forecast error
variance. Global SARIMA produces the lowest dispersion (2.5532), whereas rolling and
averaged-window approaches exhibit higher variance.
22

The log predictive score reveals an important pattern. Although Global SARIMA performs well in RMSE terms, its log score is less favorable than that of the Markov-switching
model. The MS-AR(1) specication delivers the most favorable log score (-2.1097), indicating better calibration of predictive density under recurring volatility shifts. This suggests
that explicitly modeling regime-dependent variance improves density forecasting even when
point forecast gains are small.
Table 14: Variance Recurring: 300 simulations
Method

RMSE

MAE

Bias

Variance

LogScore

SARIMA Global

1.6018

1.2311

-0.1129

2.5532

-1.8845

MS AR(1)

1.6031

1.2303

-0.1114

2.5575

-2.1097

SARIMA Rolling

1.6237

1.2554

-0.1145

2.6233

-1.8654

SARIMA Avg-Window

1.6247

1.2484

-0.0935

2.6309

-1.8874

Compared to the single-break case, forecast error variance is substantially lower in absolute terms, reecting the stochastic rather than abrupt nature of regime changes. However,
dierences across models are more closely tied to density accuracy than to point forecast
measures.
In the recurring variance environment, explicit regime modeling improves variance calibration, while point forecast dierences remain moderate. Models that assume constant
variance remain competitive in RMSE terms but may underestimate volatility dynamics, as
reected in less favorable log scores.

6

Conclusion

This study examines the performance of alternative forecasting methods under structural
instability aecting the mean, autoregressive parameter, and variance of an AR(1) process.
Using controlled Monte Carlo designs, the analysis isolates the eects of single and recurring
breaks and evaluates forecasting accuracy using both point and distributional metrics.
Across break types, several consistent patterns emerge. First, structural instability generally reduces the eectiveness of global full-sample estimators. When parameters shift,
pooling all historical observations introduces bias or excess dispersion, particularly after
breaks. This eect is most visible in the mean-break and parameter-break designs, where
global SARIMA frequently exhibits higher RMSE or error variance relative to adaptive or
regime-based alternatives.
Second, adaptive methods such as rolling estimation and window averaging improve performance when breaks alter the conditional mean or autoregressive dynamics. In single mean
and parameter break environments, rolling and break-adjusted approaches reduce forecast
dispersion and, in several cases, lower RMSE relative to global models. These gains reect
a reduction in post-break bias, although they may come at the cost of increased estimation
variance in stable segments.
Third, explicitly modeling regime changes becomes more relevant in recurring environments. For parameter breaks with high persistence, Markov-switching models provide more
23

stable performance and often achieve lower error variance. In the variance-break setting,
regime-switching specications improve density calibration, as reected in superior log predictive scores, even when point forecast dierences remain modest. This indicates that
modeling regime-dependent volatility is particularly important for predictive distribution
accuracy rather than for mean forecasts alone.
The results also highlight the role of innovation distributions. Under heavy-tailed Studentt innovations, dierences across models become more pronounced, especially in variancebreak designs. Methods that account for conditional heteroskedasticity or adapt to changing
dispersion exhibit more robust density performance relative to constant-variance specications.
No single forecasting approach dominates across all structural environments. Fixedparameter models perform adequately under stability but deteriorate in the presence of
breaks. Adaptive estimators mitigate bias after structural shifts, while regime-switching
models are better suited to persistent and recurring changes. The relative eectiveness of
each method depends on the nature, magnitude, and persistence of instability.

References
References
[1] Bai, J., & Perron, P. (1998). Estimating and testing linear models with multiple structural changes. Econometrica, 66(1), 4778.
[2] Bai, J., & Perron, P. (2003). Computation and analysis of multiple structural change
models. Journal of Applied Econometrics, 18(1), 122.
[3] Clark, T. E., & McCracken, M. W. (2005). The power of tests of predictive ability in
the presence of structural breaks. Journal of Econometrics, 124(1), 131. (Originally
circulated in 2003.)
[4] Clements, M. P., & Hendry, D. F. (1998). Forecasting Economic Time Series. Cambridge
University Press.
[5] Gardner, E. S. (1985). Exponential smoothing: The state of the art. Journal of Forecasting, 4(1), 128.
[6] Hamilton, J. D. (1989). A new approach to the economic analysis of nonstationary time
series and the business cycle. Econometrica, 57(2), 357384.
[7] HÃ¤nninen, S. (2018). Forecasting under structural breaks: Direct versus iterated forecasts. Journal of Forecasting, 37(5), 561578.
[8] Hansen, B. E. (2001). The new econometrics of structural change: Dating breaks in
U.S. labor productivity. Journal of Economic Perspectives, 15(4), 117128.

24

[9] Holt, C. C. (2004). Forecasting seasonals and trends by exponentially weighted moving
averages. International Journal of Forecasting, 20(1), 510. (Original work published
1957.)
[10] Hyndman, R. J., & Athanasopoulos, G. (2018). Forecasting: Principles and Practice
(2nd ed.). OTexts.
[11] Perron, P. (1989). The great crash, the oil price shock, and the unit root hypothesis.
Econometrica, 57(6), 13611401.
[12] Pesaran, M. H., Pick, A., & Timmermann, A. (2011). Optimal forecasts in the presence
of structural breaks. Journal of Econometrics, 164(1), 188205.
[13] Stock, J. H., & Watson, M. W. (1996). Evidence on structural instability in macroeconomic time series relations. Journal of Business & Economic Statistics, 14(1), 1130.
[14] Tian, Y. (2011). Forecast combinations under structural breaks. Journal of Forecasting,
30(6), 625648.
[15] Winters, P. R. (1960). Forecasting sales by exponentially weighted moving averages.
Management Science, 6(3), 324342.

25

